{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from pprint import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train/training_data.csv\",delimiter=\",\",header = None)\n",
    "train_label = pd.read_csv(\"../data/train/training_labels.csv\",delimiter=\",\",header = None)\n",
    "test = pd.read_csv(\"../data/test/test_data.csv\",delimiter=\",\",header = None)\n",
    "groups = pd.read_csv(\"../data/train/training_subjects.csv\",delimiter=\",\",header = None)\n",
    "t_groups = pd.read_csv(\"../data/test/test_subjects.csv\",delimiter=\",\",header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6373, 561)\n",
      "(3926, 561)\n",
      "(6373, 1)\n"
     ]
    }
   ],
   "source": [
    "pprint(train.shape)\n",
    "pprint(test.shape)\n",
    "pprint(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18])\n",
      "array([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])\n"
     ]
    }
   ],
   "source": [
    "pprint(groups[0].unique())\n",
    "pprint(t_groups[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data scaling\n",
    "Since the data is collected by subjects. All features are scaled with in subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group = 19\n",
    "test_group = 12\n",
    "\n",
    "scale_by_group(train,groups,train_group,\"train_after_scale.csv\")\n",
    "scale_by_group(test,t_groups,test_group,\"test_after_scale.csv\")\n",
    "\n",
    "del groups\n",
    "del t_groups\n",
    "\n",
    "train = pd.read_csv(\"train_after_scale.csv\",delimiter=\",\",header = None)\n",
    "test = pd.read_csv(\"test_after_scale.csv\",delimiter=\",\",header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light gradient boosting\n",
    "\n",
    "8 fold corss avlidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.179975\ttraining's multi_error: 0.0334786\tvalid_1's multi_logloss: 0.261104\tvalid_1's multi_error: 0.0423197\n",
      "[200]\ttraining's multi_logloss: 0.043553\ttraining's multi_error: 0.00209241\tvalid_1's multi_logloss: 0.20032\tvalid_1's multi_error: 0.0407524\n",
      "[300]\ttraining's multi_logloss: 0.0133672\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.208406\tvalid_1's multi_error: 0.0376176\n",
      "[400]\ttraining's multi_logloss: 0.00456149\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.230107\tvalid_1's multi_error: 0.0360502\n",
      "Early stopping, best iteration is:\n",
      "[212]\ttraining's multi_logloss: 0.0374835\ttraining's multi_error: 0.00087184\tvalid_1's multi_logloss: 0.199453\tvalid_1's multi_error: 0.039185\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.179891\ttraining's multi_error: 0.0326068\tvalid_1's multi_logloss: 0.273713\tvalid_1's multi_error: 0.0454545\n",
      "[200]\ttraining's multi_logloss: 0.0431387\ttraining's multi_error: 0.00313862\tvalid_1's multi_logloss: 0.213853\tvalid_1's multi_error: 0.0423197\n",
      "[300]\ttraining's multi_logloss: 0.0132268\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.223587\tvalid_1's multi_error: 0.0407524\n",
      "[400]\ttraining's multi_logloss: 0.00450235\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.247826\tvalid_1's multi_error: 0.0407524\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's multi_logloss: 0.0405126\ttraining's multi_error: 0.00191805\tvalid_1's multi_logloss: 0.213461\tvalid_1's multi_error: 0.0423197\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.175424\ttraining's multi_error: 0.0319093\tvalid_1's multi_logloss: 0.301176\tvalid_1's multi_error: 0.0485893\n",
      "[200]\ttraining's multi_logloss: 0.0412288\ttraining's multi_error: 0.00278989\tvalid_1's multi_logloss: 0.257849\tvalid_1's multi_error: 0.0470219\n",
      "[300]\ttraining's multi_logloss: 0.0124769\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.276719\tvalid_1's multi_error: 0.0485893\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's multi_logloss: 0.0574556\ttraining's multi_error: 0.00993897\tvalid_1's multi_logloss: 0.257405\tvalid_1's multi_error: 0.0485893\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.17726\ttraining's multi_error: 0.0331241\tvalid_1's multi_logloss: 0.290868\tvalid_1's multi_error: 0.0502355\n",
      "[200]\ttraining's multi_logloss: 0.0426026\ttraining's multi_error: 0.00244073\tvalid_1's multi_logloss: 0.242016\tvalid_1's multi_error: 0.0470958\n",
      "[300]\ttraining's multi_logloss: 0.0130007\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.25697\tvalid_1's multi_error: 0.0470958\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's multi_logloss: 0.101526\ttraining's multi_error: 0.0237099\tvalid_1's multi_logloss: 0.254338\tvalid_1's multi_error: 0.0470958\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.178247\ttraining's multi_error: 0.0315551\tvalid_1's multi_logloss: 0.285883\tvalid_1's multi_error: 0.0502355\n",
      "[200]\ttraining's multi_logloss: 0.0428332\ttraining's multi_error: 0.0027894\tvalid_1's multi_logloss: 0.224512\tvalid_1's multi_error: 0.0486656\n",
      "[300]\ttraining's multi_logloss: 0.0131075\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.23561\tvalid_1's multi_error: 0.0470958\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's multi_logloss: 0.0445083\ttraining's multi_error: 0.00313808\tvalid_1's multi_logloss: 0.224495\tvalid_1's multi_error: 0.0486656\n",
      "fold 5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.179378\ttraining's multi_error: 0.0327755\tvalid_1's multi_logloss: 0.273866\tvalid_1's multi_error: 0.0486656\n",
      "[200]\ttraining's multi_logloss: 0.0431805\ttraining's multi_error: 0.00261506\tvalid_1's multi_logloss: 0.213922\tvalid_1's multi_error: 0.0455259\n",
      "[300]\ttraining's multi_logloss: 0.0132276\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.224056\tvalid_1's multi_error: 0.0455259\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's multi_logloss: 0.0922599\ttraining's multi_error: 0.0233612\tvalid_1's multi_logloss: 0.226682\tvalid_1's multi_error: 0.043956\n",
      "fold 6\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.175354\ttraining's multi_error: 0.0312064\tvalid_1's multi_logloss: 0.302755\tvalid_1's multi_error: 0.0533752\n",
      "[200]\ttraining's multi_logloss: 0.0415273\ttraining's multi_error: 0.00226639\tvalid_1's multi_logloss: 0.270943\tvalid_1's multi_error: 0.0518053\n",
      "[300]\ttraining's multi_logloss: 0.0125886\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.297993\tvalid_1's multi_error: 0.0502355\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's multi_logloss: 0.063436\ttraining's multi_error: 0.0116806\tvalid_1's multi_logloss: 0.26683\tvalid_1's multi_error: 0.0533752\n",
      "fold 7\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.179544\ttraining's multi_error: 0.0327755\tvalid_1's multi_logloss: 0.242911\tvalid_1's multi_error: 0.032967\n",
      "[200]\ttraining's multi_logloss: 0.0436052\ttraining's multi_error: 0.00261506\tvalid_1's multi_logloss: 0.174662\tvalid_1's multi_error: 0.0345369\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's multi_logloss: 0.663647\ttraining's multi_error: 0.0399233\tvalid_1's multi_logloss: 0.688662\tvalid_1's multi_error: 0.0313972\n",
      "fold 8\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.178412\ttraining's multi_error: 0.0326011\tvalid_1's multi_logloss: 0.275281\tvalid_1's multi_error: 0.0470958\n",
      "[200]\ttraining's multi_logloss: 0.0427993\ttraining's multi_error: 0.00209205\tvalid_1's multi_logloss: 0.218655\tvalid_1's multi_error: 0.043956\n",
      "[300]\ttraining's multi_logloss: 0.0131617\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.230366\tvalid_1's multi_error: 0.0423862\n",
      "[400]\ttraining's multi_logloss: 0.00447739\ttraining's multi_error: 0\tvalid_1's multi_logloss: 0.254415\tvalid_1's multi_error: 0.0423862\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's multi_logloss: 0.0396982\ttraining's multi_error: 0.0013947\tvalid_1's multi_logloss: 0.218386\tvalid_1's multi_error: 0.043956\n",
      "fold 9\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.1808\ttraining's multi_error: 0.0326011\tvalid_1's multi_logloss: 0.24015\tvalid_1's multi_error: 0.032967\n",
      "[200]\ttraining's multi_logloss: 0.0442691\ttraining's multi_error: 0.00226639\tvalid_1's multi_logloss: 0.177309\tvalid_1's multi_error: 0.032967\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's multi_logloss: 0.52521\ttraining's multi_error: 0.0388773\tvalid_1's multi_logloss: 0.543513\tvalid_1's multi_error: 0.0313972\n",
      "0.9570061195669229\n"
     ]
    }
   ],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "train_columns = train.columns.values\n",
    "\n",
    "params = {'num_leaves': 17,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective':'multiclass',\n",
    "         'learning_rate': 0.03,\n",
    "         'max_depth': 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"metric\": 'multi_error',\n",
    "         \"lambda_l2\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 42}\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "y_pred = np.zeros(len(test))\n",
    "#feature_importance_df = pd.DataFrame()\n",
    "#run model\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train,train_label.values)):\n",
    "    strLog = \"fold {}\".format(fold_)\n",
    "    print(strLog)\n",
    "    \n",
    "    X_tr, X_val = train.iloc[trn_idx], train.iloc[val_idx]\n",
    "    y_tr, y_val = train_label.iloc[trn_idx], train_label.iloc[val_idx]\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params, n_estimators = 1300, n_jobs = -1)\n",
    "    model.fit(X_tr, \n",
    "              y_tr.loc[:,0], \n",
    "              eval_set=[(X_tr, y_tr.loc[:,0]), (X_val, y_val.loc[:,0])], \n",
    "              eval_metric=['multi_error','multi_logloss'],\n",
    "              verbose=100, \n",
    "              early_stopping_rounds=200)\n",
    "    oof[val_idx] = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "    y_pred += model.predict(test,num_iteration=model.best_iteration_)/n_fold\n",
    "\n",
    "pprint(accuracy_score(oof,train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(oof)\n",
    "df = pd.DataFrame(y_pred)\n",
    "y_pred = thresholding(y_pred,0.3)\n",
    "to_submission(y_pred,\"redo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble model\n",
    "out of fold hill climb ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post-processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
